# output and name
run_name: sft_smol135m
output_dir: sft_smol135m
hub_model_id: SmolLM2-135M-tldr-sft
output_global_parent_dir: /network/scratch/n/noukhovm/rlhf-bpo/results
wandb_run_id: slurm
push_to_hub: True
# tldr stuff
model_name_or_path: HuggingFaceTB/SmolLM2-135M
dataset_name: trl-lib/tldr
dataset_test_split: validation
report_to: wandb
learning_rate: 1e-5
bf16: True
torch_dtype: bfloat16
lr_scheduler_type: cosine
gradient_accumulation_steps: 4
per_device_train_batch_size: 32
per_device_eval_batch_size: 8
num_train_epochs: 1
gradient_checkpointing: False
eval_strategy: "steps"
eval_steps: 0.2
logging_steps: 100
ddp_find_unused_parameters: False
